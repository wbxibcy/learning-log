# 2022-5-16

## 模型的一生

在`pr-pytorch`的`jupyterlab`的`快速入门`

## batch_size = 64

(一次可以读取的系列的大小)

## 损失函数

crossEntropy
交叉熵

## 优化器

SGD

## epoch

epoch = train + test
纪元或期次
batch < epoch
(类似C语言中的双层for循环)

## 安装深度学习的框架

安装`pytorch`
[pytorch](https://pytorch.org/get-started/locally/#windows-python)

## 下载所需要的jupyterlab

`mkdir d2l-zh && cd d2l-zh`
(创建一个文件夹，并且进入)
`curl https://zh-v2.d2l.ai/d2l-zh-2.0.0.zip -o d2l-zh.zip`
(下载这个压缩包，并且重命名)
`unzip d2l-zh.zip && rm d2l-zh.zip`
(解压并且删除)
在本目录下，打开jupyterlab

## 有关问题

安装PyTorch后jupyter lab中仍出现“No module named torch“
`conda install jupyter`或`conda install jupyterlab`
`conda install nb_conda`(关键)
`jupyter lab`

[google](https://aitechtogether.com/ai-question/9379.html)

### 关闭jupyterlab

快捷键`ctrl+c`

## 安装d2l的软件包

1. 在`pypi`中找到这个软件包，下载`.whl`文件
   [pypi](https://pypi.org/project/d2l/#files)
2. 打开到那个文件所在的目录
   [csdn](https://blog.csdn.net/qq_15969343/article/details/79055603)
3. `pip install 文件`
   (如速度慢，可加个镜像)
   `pip install d2l-0.17.5-py3-none-any.whl -i http://pypi.douban.com/simple --trusted-host pypi.douban.com`
   [csdn](https://blog.csdn.net/mario12315/article/details/108118369?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-108118369-blog-79055603.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-108118369-blog-79055603.pc_relevant_default&utm_relevant_index=1)

## 是否装驱动

命令行`driverquery`

## 如何判断有无NVIDIA的显卡

1. 打开`任务管理器`
2. 点击`性能`
- 有`NVIDIA`的名字  有
- 无`NVIDIA`的名字  无

## 安装GPU版本的pytorch

1. 确定自己的`算力`

2. 确定自己可选择的`CUDA Runtime Versiob`

3. 确保`CUDA Driver`的版本 >=  `CUDA Runtime`版本

4. 去`pytorch`的官网查找安装口令
   
   ### 
   
   `CUDA Driver`一般在显卡驱动里面

### 如何确定自己的`CUDA Driver`的版本

1. 打开终端
2. 输入`nvidia-smi`

## 测试是否有`GPU`版本的`pytorch`

1. `conda list`
   (查找是否有`pytorch`)
2. `python`
3. `import torch`
4. torch.cuda.is_available()
- 如果有，结果为`True`
- 如果没有，结果为`False`

## 从`github`下载包(以`pandas-datareader`为例)

`git clone https://github.com/pydata/pandas-datareader.git`
`cd pandas-datareader`
`python setup.py install`
先从`github`拉下来，再下载

### 

`pip insatll 包`
和
下载包到本地
`pip install 本地文件`
相通

## pip 临时配网络

`pip install numpy --proxy socks5://127.0.0.1:7890`
(proxy参数（前面是两个减号）)
(7890是代理的端口号)
[jpg](C:\Users\sunw\Desktop\软件\数据科学\实验室)

## 线性回归

损失函数：
平方误差损失函数

## softmax回归

实现`softmax回归`的三个步骤

1. 对每个项求幂（使用exp）；
2. 对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数；
3. 将每一行除以其规范化常数，确保结果的和为1。

分类精度 

- 分类精度即正确预测数量与总预测数量之比

## 损失函数

1. `L2loss`
   (均分损失)

2. `L1loss`
   (绝对值损失)

3. `Huber's Robust loss`
   (L1loss和L2loss的结合体)

## 感知机

是一个`二分类`的模型，最早的`AI模型`之一
求解算法：等价于使用批量大小为`1`的梯度下降
缺点：不能拟合`XOR`函数，导致了第一次`AI寒冬`

## 多层感知机(MLP)

1. 使用隐藏层和激活函数来得到非线性模型
2. 使用`softmax`来处理多类分类
3. 超参数是隐藏层数和各隐藏层大小

### 常用的激活函数

- `Sigmoid`
- `Tanh`
- `ReLu`

### SGD

随机梯度下降

## 误差

1. 训练误差
- 模型在训练数据集上计算得到的误差
2. 泛化误差
- 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望
  (训练误差就是在训练的时候出现的误差，泛化误差就是在模型在新的数据上的误差)
  (关心的其实是泛化误差)

### 影响泛化误差的几个因素

1. 可调整参数的数量。当可调整参数的数量（有时称为自由度）很大时，模型往往更容易过拟合。

2. 参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。

3. 训练样本的数量。即使你的模型很简单，也很容易过拟合只包含一两个样本的数据集。
   而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。
   (训练样本的数量太少)

## 数据集

- 验证数据集
  用来评估模型好坏的数据集
  (不是训练数据集)
- 测试数据集
  只用一次的数据集

## 解决数据数量不够的问题

### K折交叉验证

1. 将数据集分成K块
2. `for`循环
   例如:
   K = 3

当i = 1时
第一块为验证数据集
第二三块为训练数据集

当i = 2时
第二块为验证数据集
第一三块为训练数据集

当i = 3时
第三块为验证数据集
第一二块为训练数据集

误差就为三个验证数据集的误差的平均

### 训练数据集

训练模型参数

### 验证数据集

选择模型超参数

## 模型容量(难以在不同种类的模型中比较)

2个主要因素

1. 参数的个数
2. 参数值的选择范围

## 数据复杂度

1. 样本的个数
2. 每个样本的元素个数
3. 时间、空间结构
4. 多样性

#### 

模型容量要匹配数据复杂度，否则会导致欠拟合或者过拟合

## 权重衰退

数学方法：拉格朗日乘子法

### 做法

添加一个L2范数惩罚项

### 目的

将参数的范围变小，从而降低模型容量，来应对过拟合

## 丢弃法

将输出项随机置`0`来控制模型的复杂度
一般用于神经网络的**隐藏层**
丢弃的概率是模型的一个超参数

## 数值稳定性

1. 梯度爆炸
2. 梯度消失

#### diag

对角矩阵

### 梯度爆炸的问题

- 值会超出值域(infinity)
  在16位浮点数时尤为明显(6e-5~6e4)(区间不大)
- 对学习率敏感
  1. 学习率太大 -> 参数值大 -> 更加大的梯度 -> 梯度爆炸
  2. 学习率太低 -> 训练毫无进展
     (所以， 我们需要在训练过程中不断调整学习率，但是学习率也会变得很难调)

### 梯度消失的问题

- 梯度值变成零
  对于16位浮点数尤为严重(又要迫害16位浮点数了)
- 训练没有进展
  学习率在这里就没有用了
- 对于底部层尤为严重
  顶部层的训练蛮好
  无法使神经网络更加深

#### 总结

- 当数值过大或者过小的时候，都会导致数值的问题
- 常常发生在深度模型中，因为在深度模型中会对`n`个数**累乘**

## 训练稳定

目标：让梯度在一个合理的范围内
措施：

1. 将乘法变成加法
   - ResNet, LSTN
2. 归一化
   - 梯度归一化，将梯度裁剪
3. 合理的权重初始和激活函数

### 合理的权重初始和激活函数

- 将每层的输出和梯度都看成随机变量
- 让它们的均值和方差都保持一致

### 权重初始化

- 在合理值区间里随机初始参数
- 在训练一开始的时候很容易会有数值不稳定的情况
  - 远离最优解的地方损失函数表面可能很复杂
  - 而最优解附近表面会比较平

#### 激活函数

首选`Relu`
其次`tanh`
如果要选`sigmoid`,可将其进行线性变换，例如：运用`4*sigmoid(x)-2`这个激活函数
(`Relu`函数就是为了解决梯度消失而出现的激活函数)

### 总结

合理的权重初始值和激活函数的选取可以提升数值稳定性，可以有效的防止梯度消失和梯度爆炸

#### pip 安装 换源

```yaml
 阿里源：https://mirrors.aliyun.com/pypi/simple/
 清华源：https://pypi.tuna.tsinghua.edu.cn/simple/
 豆瓣：http://pypi.douban.com/simple/
 中科大： https://pypi.mirrors.ustc.edu.cn/simple/
```

示例:`pip install autogluon -i https://mirrors.aliyun.com/pypi/simple/`

## 层和块

### 层:

例如，`softmax回归`是一个单层，但是它也是一个模型，所以，单个层也可以是一个模型(较简单罢了)

### 块

块（block）可以描述单个层、由多个层组成的组件或整个模型本身。
块可以认为是层的组合体

#### 小结

- 一个`块`可以由许多`层`组成；一个`块`可以由许多`块`组成。
- `块`可以包含代码。
- `块`负责大量的内部处理，包括参数初始化和反向传播。
- `层`和`块`的顺序连接由`Sequential`块处理。

#### python 里的super().__init__()

继承父类的init的方法

### 关于Sequential

其实可以认为是个python的列表
例如：

```yaml
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))
X = torch.rand(size=(2, 4))
print(net[2].state_dict())
```

结果：
`OrderedDict([('weight', tensor([[ 0.0425,  0.2304, -0.0954, -0.2109, -0.0345, -0.0479,  0.3346, -0.1201]])), ('bias', tensor([-0.1229]))])`
(结果不是唯一的，因为，X是个随机数)

解析：
`net(2)`是`nn.Linear(8, 1)`，看结果就可以知道，结果为一个`tensor`,而`state_dict`是一个状态字典，对于线性回归来讲,
它的状态字典就是权重(Weight)和偏移(bias)。

#### applyh函数(pandas中的灵活，但是有用的函数)

举个例子:

```python
# 对列进行操作(对行进行操作也是类似的)
data=np.arange(0,16).reshape(4,4)
data=pd.DataFrame(data,columns=['0','1','2','3'])
def f(x):
    return x-1
print(data)
print(data.ix[:,['1','2']].apply(f))
# 结果
    0   1   2   3
0   0   1   2   3
1   4   5   6   7
2   8   9  10  11
3  12  13  14  15
    1   2
0   0   1
1   4   5
2   8   9
3  12  13
```

### 查看层

```python
# 查看第一个全连接层
print(*[(name, param.shape) for name, param in net[0].named_parameters()])

# 查看所有的全连接层
print(*[(name, param.shape) for name, param in net.named_parameters()])
```

注意：
`*号`是`解包`操作
背后原理：
先用`[]`运算符将他变成`list`，再运用`*号`来进行`解包`操作

### 保存和加载向量(并不是只有向量可以保存和下载，张量或者是字典都可以)

- 保存
  torch.save()这个函数
  例子:
  
  ```python
  x = torch.arange(4)
  torch.save(x, 'x-file')
  ```

- 下载
  torch.load()这个函数
  例子：
  
  ```python
  x2 = torch.load('x-file')
  ```

### 保存模型

保存模型其实不是将模型的定义给保存下来，其实是将一个模型的参数给保存下来，
以MLP为例子，可以将参数保存下来，接着，想要使用的话，
就可以将模型先实例化，然后将参数下载下来就好。
注意:

1. 保存还是使用`torch.save()`
   但是下载就要使用`torch.load_state_dict`

### 小结

- `save`和`load`函数可用于**张量**对象的文件读写。
- 我们可以通过`参数字典`保存和`加载网络`的全部参数。
- 保存架构必须在代码中完成，而不是在参数中完成。

## 卷积神经网络

有两个原则:

1. 平移不变性

2. 局限性
   
   ### 小结
- 图像的`平移不变性`使我们以相同的方式处理局部图像，而不在乎它的位置。
- `局部性`意味着计算相应的隐藏表示只需一小部分局部图像像素。
- 在图像处理中，卷积层通常比全连接层需要**更少**的参数，但依旧获得高效用的模型。
- `卷积神经网络（CNN）`是一类特殊的神经网络，它可以包含多个卷积层。
- 多个`输入`和`输出`通道使模型在`每个空间位置`可以获取图像的`多方面特征`。
1. 卷积层将输入和核矩阵进行交叉相关，加上偏移后得到输出
2. 核矩阵和偏移是可学习的参数
3. 核矩阵的大小是超参数

## 填充和步幅

1. `填充`和`步幅`是卷积层的超参数
2. 填充:
   在输入的周围添加额外的行/列,来控制输出形状的减少量
3. 步幅:
   每次滑动`核矩阵窗口`的行/列的`步长`,可以成倍的减少输出形状

## 多输入和多输出通道

1. `输出通道数`是卷积层的`超参数`
2. 每个`输入通道`有独立的`二维`卷积核，所有通道结果相加得到`一个输出通道结果`
3. 每个输出通道有独立的三维卷积核

## 池化层

- 池化层返回窗口中`最大`或者`平均值`
- 缓解卷积层对位置的敏感性
- 有`窗口大小、填充、和步幅`作为超参数

## LeNet

- 是早期成功的神经网络
- 先使用卷积层来学习图片空间信息
- 然后使用`全连接层`来转换类别空间

## AlexNet

- AlexNet是更大更深的LeNet，10x参数个数，260x计算复杂度
- 新加入了`丢弃法`，`ReLU`,`最大池化层`和`数据增强`

## VGG

- `VGG`使用**可重复使用**的卷积块来构建深度卷积深度神经网络
- 不同的卷积块个数和超参数可以得到不同复杂度的变种
- 不同的`VGG`模型可通过每个块中卷积层数量和输出通道数量的差异来定义
- 块的使用导致网络定义的非常简洁。使用块可以有效地设计复杂的网络。
- 在VGG论文中，他们发现深层且窄的卷积(即3x3)比较浅层且宽的卷积更加有效
  所以，**深且窄**的才是`yyds`

## NiN块

- `NiN`块使用卷积层加两个1x1卷积层，后者对每个像素增加了非线性性
- `NiN`使用`全局平均池化层`来替代全连接层，这样的好处在于拥有更加少的参数，
  (`类别数`就是`全局平均池化层`的`输出通道数`)
  在之前的`VGG`和`AlexNet`中，不管如何调参，都或多或少的有过拟合的问题，
  现在运用`NiN块`的话，就会不容易过拟合，而且还会有**更加少**的参数个数。

## GoogLeNet

1. `Inception`块用`4`条不同超参数的卷积层和池化层的路来抽取不同的信息
   - 它的一个主要优点是模型参数小，计算复杂度低
2. `GoogLeNet`使用了`9`个`Inception`块，是**第一个**达到上百层的网络

## 批量归一化(batchnorm)

- 在模型训练过程中，批量规范化利用小批量的均值和标准差，不断调整神经网络的中间输出，使得整个神经网络各层的中间输出值更
  加稳定
- 批量规范化在全连接层和卷积层的使用略有不同。
- 批量规范化层和`dropout层`一样，在训练模式和预测模式下计算不同。
- 批量规范化有许多有益的副作用，主要是`正则化`。另一方面，“减小内部协变量偏移”的原始动机似乎不是一个有效的解释。

## ResNet

- 残差块使得很深的网络更加容易训练，甚至可以训练1000层的网络
- 残差网络对随后的深层神经网络设计产生了深远影响，无论是卷积类网络还是全连接类网络。

## CPU和GPU

- CPU：
  可以处理通用计算。性能优化考虑数据读写效率和多线程
- GPU：
  使用更多的小核和更多的内存带宽，适合能大规模并行的计算任务

## 数据增强

1. 数据增广通过变形数据来罗德多样性从而使得模型泛化性能更好
2. 常见图片增广包括翻转、切割、变色

## 微调

- 微调通过使用在大数据上得到的预训练好的模型来初始化模型权重来完成提升精度
- 预训练模型质量很重要
- 微调通常熟读更快、精度更高

## #Pytorch报错# PytorchStreamReader failed reading zip archive failed finding central directory 的解决办法

- 删除`C:\Users\用户名/.cache\torch\hub\checkpoints.pth权重文件`

## 物体检测

- 物体加测识别图片里的多个物体的类别和位置
- 位置通常用边缘框表示
- 常见的数据集就是`COCO`

## 目标检测

### 交并比(IoU)

- 给定两个集合`A`和`B`
- 两个集合的`交集`和`并集`的`比值`
  (越接近`1`，`相似度`就越`好`)

### NMS

用来合并一些相似的预测

#### NMS具体实现

1. 选取这类box中scores最大的那一个，记为box_best,并且保留它
2. 计算box_best与其他box的IOU
3. 如果IOU大于某个值(这个值是自己设的，一般是0.5)，那么就舍弃这个box
4. 从最后剩余的boxes中，再找出最大scores的那一个，如此反复循环

## 总结

- 一类目标检测算法基于`锚框`来预测
- 首先生成大量`锚框`，并且`赋予标号`，`每个锚框`作为`一个样本`来进行训练
- 在预测的时候，使用`NMS`来去除冗余的`预测`

## Kaggle树叶分类总结

- 提升精度思路：根据数据挑选增强，使用新模型、新优化算法，多个模型融合，测试时使用增强
- 数据相对简单
- 在工业界应用中：
  - 少使用模型融合和测试时增强，计算代价过高
  - 通常固定模型超参数，将精力主要花在提升数据质量

## R-CNN

- R-CNN是最早、也是最有名的一类基于锚框和CNN的目标检测算法
- Fast/Faster R-CNN持续提升性能
- Faster R-CNN和Mask R-CNN是在最求高精度场景下的常用算法

## SSD

- SSD通过单神经网络来检测模型
- 以每个像素为中心的产生多个锚框
- 在多个段的输出进行多尺度的检测

## 语义分割

语义分割指的是将图像中的每个像素关联到一个类别标签上的过程

### 语义分割VS实例分割

- 语义分割就将不同的类分开来，实例分割将每个实例都分割出来
- 举个例子：将猫（包含不同品种的猫）和狗（包含不同品种的狗）分开，就是语义分割；而将哈士奇、柯基、美短和英短分开，就是实例分割

#### 语义分割数据集

- `PascalVOC2012`

### 语义分割小结

- 语义分割通过将图像划分为属于不同语义类型的区域，来识别并理解图像中像素级别的内容。
- 语义分割的一个重要的数据集叫做`PascalVOC2012`
- 由于语义分割的输入图像和标签在像素上一一对应，输入图像会被随机裁剪为固定尺寸而不是缩放。

## 转置卷积

- 与通过卷积核减少输入元素的常规卷积相反，转置卷积通过卷积核广播输入元素，从而产生形状大于输入的输出。
- 可以使用矩阵乘法来实现卷积。转置卷积层能够交换卷积层的正向传播函数和反向传播函数。

## 全连接卷积神经网络(FCN)

- FCN是用深度神经网络来做语义分割的奠基性工作
- 它用转置卷积层来替代CNN最后的全连接层，从而可以实现每个像素的预测

### 在torchvision中要更新参数和报错

- 在新版本中，可以指定权重，已经抛弃了之前的写法
  [csdn](https://blog.csdn.net/Sihang_Xie/article/details/125646287)

## 样式迁移

将图片的样式结构提取出来，将另外一张图片的内容提取出来，然后合起来，就变成了一个新的图片

## 时间序列

- 再时间t观察到x，那么会有T个不独立的`随机变量`
- 那么可以使用`条件概率`来展开

### 马尔科夫假设

- 假设当前的数据只和x个过去数据点相关
- 例如：明天的股票只和一个月前的数据有关，和1年前的数据就没又多大关系了

### 潜变量模型

引入潜变量h来表示过去信息

### 总结

- 在时序模型中，当前数据跟之前观察到的数据相关
- 自回归模型使用自身过去数据来预测未来
- 马尔科夫模型假设当前只跟最近少数数据相关，从而简化模型
- 潜变量模型使用潜变量来概括历史信息

### 小结

- `内插法`(在现有观测值之间进行估计)和`外推法`(对超出已知观测范围进行预测)在实践的难度上差别很大。因此，对于你所拥有的序列数据，在训练时始终要尊重其时间顺序，即最好不要基于未来的数据进行训练。
- `序列模型`的估计需要专门的统计工具，两种较流行的选择是`自回归模型`和`隐变量自回归模型`。
- 对于时间是向前推进的因果模型，正向估计通常比反向估计更容易。
- 对于知道时间步t的观测序列，其在时间步t + k的预测输出是“K步预测”。随着我们对预测时间k值的增加，会造成误差的快速积累和预测质量的极速下降。

## 文本预处理(一般步骤)

1. 将文本作为字符串加载到内存中。
2. 将字符串拆分成`词元`(如单词和字符)
3. 建立一个词典，将拆分的词元映射到数字索引。
4. 将`文本`转换为`数字索引序列`，方便模型操作。

## 语言模型

- 语言模型估计文本序列的联合概率
- 使用统计方法时常采用`n元语法`

## RNN

- 语言模型
- 衡量一个语言模型可以使用`平均交叉熵`
  历史原因NLP使用`困惑度`(perplexity)来衡量，是平均每次可能选项
  1表示完美，无穷大是最差的情况

### 梯度裁剪

- 迭代中计算这T个时间步上的梯度，在反向传播过程中产生长度为O(T)的矩阵乘法链，导致数值不稳定
- 梯度裁剪能有效预防梯度爆炸
  - 如果梯度长度超过一个值(x)，那么变成(x)
  - 例如，全部梯度为g，那么，首先在1和(x/||g||)之间取最小值，再乘以g
  - 所以，如果梯度长度超过x，那么拖影回长度x

### RNN总结

- 循环神经网络的输出取决于当下输入和前一时间的潜变量
- 应用到语言模型中，循环神经网络根据当前词预测下一次时刻词
- 通常使用困惑度来衡量语言模型的好坏

### RNN的简洁实现

1. 深度学习框架的高级API提供了循环神经网络层的实现
2. 高级API的循环神经网络层返回一个输出和一个更新后的隐状态，我们还需要激素那整个模型的`输出层`

## GRU(门控循环单元)

- 门控循环神经网络可以更加好的获得时间步距离很长的序列上的依赖关系
- 重置门有助于捕获序列中的短期依赖关系
- 更新门有助于捕获序列中的长期依赖关系
- 重置门打开是，门控循环单元包括基本神经网络；更新门打开时，门控循环单元可以跳过子序列

## 长短期记忆网络

- 忘记门：将值朝`0`减少
- 输入门：决定是不是忽略掉输入数据
- 输出门：决定是不是使用隐状态
1. 长短期记忆网络的隐藏层输出包括“隐状态”和“记忆元”。只有隐状态会传递到输出层，而记忆元完全属于内部信息。
2. 长短期记忆网络可以`缓解`梯度消失和梯度爆炸。

## 深度循环神经网络

- 深度循环神经网络使用多个隐藏层来获得更多的非线性

## 双向循环神经网络

- 双向循环神经网络通过反向更新的隐藏层来利用方向时间信息
- 通常用来对序列抽取特征、填空，而不是预测未来

## 编码器和解码器

在CNN中

- 编码器：将输入编程成中间表达形式(特征)
- 解码器：将中间表示解码成输出
  在RNN中
- 编码器：将文本表示成向量
- 解码器：向量表示成输出
  总结：
- 编码器处理输入
- 解码器生成输出

## seq2seq

- 衡量生成序列的好坏——BLEU

### 总结

- `seq2seq`从一个句子生成另外一个句子
- 编码器和解码器都是`RNN`
- 将编码器最后时间隐状态来初始解码器隐状态来完成信息传递
- 常用`BLEU`来衡量生成序列的好坏

## 束搜索

- 在每次搜索时保存K个最好的候选
- `K = 1`的时候是贪心算法
- `K = n`的时候是穷举算法

## 注意力分数

- 注意力分数是`query`和`key`的相似度，注意力权重是分数的`softmax`结果
- 两种常见的分数计算：
  - 将query和key合并起来进入一个`单输出单隐藏层的MLP`
  - 直接将query和key做`内积`

## Transformer

- 是一个纯使用注意力的编码-解码器
- 编码器和解码器都有`n`个transformer块
- 每个块里使用多头注意力，基于位置的前馈网络，和`层`归一化

## BERT

可以简单的认为，BERT是一个只有编码器的Transformer

## 总结

- BERT针对`微调`设计
- 基于T`ransformer的编码器`做修改
  - 模型更加大，训练数据更多
  - 输入句子对，片段嵌入，可学习的位置编码
  - 训练时使用两个任务
    1. 带掩码的语言模型 
    2. 下一个句子预测

