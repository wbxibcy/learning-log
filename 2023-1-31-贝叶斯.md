# 2023-1-31

## 介绍

贝叶斯分类器是一类分类算法的总称，**贝叶斯定理**是这类算法的核心，因此统称为**贝叶斯分类**。

## 贝叶斯决策论

贝叶斯决策论(Bayesian decision theory)是概率框架下实施决策的基本方法。机器学习所要实现的是基于有限的训练样本尽可能准确地估计出**后验概率** p(c|x) 。而估计后验概率的方式有两种：

- 判别式模型(discriminative models)，通过直接建模P(c|x) 来预测，其中决策树，BP神经网络，支持向量机都属于判别式模型
- 生成式模型(generative models)，通过对联合概率模型P(x，c)进行建模，然后再获得P(c|x) 。贝叶斯方法就是基于生成式模型构建的。

### 贝叶斯公式

​					$p(c \mid x)=\frac{p(x, c)}{p(x)}=\frac{p(c) p(x \mid c)}{p(x)}$

### 最优性

贝叶斯决策论选择后验概率中最大的哪一个作为预测结果，这保证了我们预测的错误概率是最小的，这就是其“最优”性。

### 参数估计

**极大似然估计（Maximum Likelihood Estimation，MLE）和贝叶斯估计（Bayesian Estimation）是统计推断中两种最常用的参数估计方法**，这两种方法，也分别是频率派和贝叶斯派的观点

## 极大似然估计

假设我们有训练集**X**，共有n个独立同分布的样本**x1**, **x2** ,… ，**θ** 表示模型的参数，也可以说是整个模型。那么，我们可以得到，在这个模型中，出现这个**n**个样本的概率为：

​												$L(X \mid \theta)=f\left(x_1, x_2, \ldots \ldots \mid \theta\right)=f\left(x_1 \mid \theta\right) \cdot f\left(x_2 \mid \theta\right) \cdots f\left(x_n \mid \theta\right)$

当概率$ p(x_1,x_2,……|\theta)$ 最大时，我们就能够得到最符合这个模型的参数$ \theta$ 。

需要注意的是，连乘容易造成下溢，我们一般将其转换成对数的形式$ ln L(X|\theta) = \sum_{x_i \in X} ln f(x_i|\theta)$

我们可以得到我们要的参数$ \theta_{MLE} = argmax_{\theta} ln L(X|\theta)$

## 朴素贝叶斯

采用了一个很重要的假设，<strong>假设所有的属性都是互相独立的(属性条件独立性假设）</strong>，即：对于联合概率有$ p(x,y) = p(x)p(y)$

朴素贝叶斯分类器的训练过程，就是基于训练集D来估计类先验概率$ P(c)$ ，并为每个属性估计条件概率$ P(x_i|c)$ 。

### 拉普拉斯修正

为了避免其他属性携带的信息被训练集中未出现的属性值”抹去”，在估计概率时通常要进行”平滑”。

- 举例：

  用极大似然估计可能会出现所要估计的==概率值为0==的情况，这时会影响到后验概率的计算结果，使得分类产生偏差。

## 半朴素贝叶斯分类器

半朴素贝叶斯分类器**对属性条件独立性假设进行了一定程度的放松**。半朴素贝叶斯分类器**适当考虑一部分属性间的相互依赖信息**，从而既不需要进行完全联合概率计算，又不彻底忽略了比较强的属性依赖关系。

### 独依赖估计

独依赖估计是半朴素贝叶斯分类器最常用的策略，就是假设每个属性在类别之外**最多只依赖一个其他属性**。

最直接的方法，就是假设所有的属性都依赖于同一个属性，称为“超父”，通过交叉验证等模型选择方法来确定超父属性，即：“SPODE”方法

### TAN

TAN(Tree Augmented naive Bayes)是在最大带权生成树算法的基础上，通过下列步骤将属性间依赖关系约简为树形结构的

### **AODE**

AODE(Averaged One-Dependent Estimator)是**基于集成学习**机制，更为强大的独依赖分类器，与SPODE通过模型选择超父属性不同，AODE尝试将每个属性作为超父来构建SPODE,然后将那些具有足够训练数据支撑的SPODE集成起来作为最终结果。



